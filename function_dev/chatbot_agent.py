# RAG ê¸°ë°˜ ì—ì´ì „íŠ¸: ë‰´ìŠ¤/ë…¼ë¬¸ ìš”ì•½ + ì§ˆì˜ì‘ë‹µ + í‚¤ì›Œë“œ/ì¶œì²˜ ì¶”ì¶œ + ë¹„êµê¸°
# ------------------------------------------------

import os
import numpy as np
import faiss
from dotenv import load_dotenv
from langchain.vectorstores import FAISS
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.chains import RetrievalQA
from langchain.agents import Tool, initialize_agent, AgentType
from langchain.chat_models import ChatOpenAI
from langchain.docstore.document import Document
from langchain.vectorstores import FAISS as FAISS_LC

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
EMBEDDING_MODEL = "sentence-transformers/all-MiniLM-L6-v2"
FAISS_INDEX_PATH = "faiss_index"
CHUNK_SAVE_PATH = "doc_chunks.npy"

# ì„ë² ë”© ëª¨ë¸ & ë²¡í„° DB ë¡œë”©
embedding_model = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL)
chunks = np.load(CHUNK_SAVE_PATH, allow_pickle=True)
texts = [chunk["text"] for chunk in chunks if isinstance(chunk, dict)]
documents = [Document(page_content=t) for t in texts]
vectordb = FAISS_LC.from_documents(documents, embedding=embedding_model)

# ì²­í¬ í•„í„°ë§ í•¨ìˆ˜
def get_chunks_by_type(source_type):
    return [c for c in chunks if isinstance(c, dict) and c.get("source") == source_type]

# ë‰´ìŠ¤ ìš”ì•½
def summarize_news(*args, **kwargs):
    news_chunks = get_chunks_by_type("news")
    if not news_chunks:
        return "ì˜¤ëŠ˜ ë‰´ìŠ¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
    texts = [c["text"] for c in news_chunks[:5]]
    joined = "\n\n".join(texts)
    prompt = f"ë‹¤ìŒì€ ìµœê·¼ ë‰´ìŠ¤ì…ë‹ˆë‹¤. ì£¼ìš” ë‚´ìš©ì„ ìš”ì•½í•´ ì£¼ì„¸ìš”.\n\n{joined}"
    llm = ChatOpenAI(temperature=0.3, openai_api_key=OPENAI_API_KEY)
    return llm.predict(prompt)

# ë…¼ë¬¸ ìš”ì•½
def summarize_papers(*args, **kwargs):
    paper_chunks = get_chunks_by_type("paper")
    if not paper_chunks:
        return "ë…¼ë¬¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
    texts = [c["text"] for c in paper_chunks[:5]]
    joined = "\n\n".join(texts)
    prompt = f"ë‹¤ìŒì€ ìµœê·¼ ë…¼ë¬¸ ë‚´ìš©ì…ë‹ˆë‹¤. í•µì‹¬ ë‚´ìš©ì„ ìš”ì•½í•´ ì£¼ì„¸ìš”.\n\n{joined}"
    llm = ChatOpenAI(temperature=0.3, openai_api_key=OPENAI_API_KEY)
    return llm.predict(prompt)

# ë‰´ìŠ¤ í‚¤ì›Œë“œ ì¶”ì¶œ
def extract_news_keywords(*args, **kwargs):
    news_chunks = get_chunks_by_type("news")
    if not news_chunks:
        return "í‚¤ì›Œë“œ ì¶”ì¶œí•  ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤."
    texts = [c["text"] for c in news_chunks[:5]]
    joined = "\n\n".join(texts)
    prompt = f"ë‹¤ìŒ ë‰´ìŠ¤ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œë¥¼ 5~10ê°œ ì¶”ì¶œí•´ì¤˜. í‚¤ì›Œë“œë§Œ ë‚˜ì—´í•´ì¤˜.\n\n{joined}"
    llm = ChatOpenAI(temperature=0.3, openai_api_key=OPENAI_API_KEY)
    return llm.predict(prompt)

# ë‰´ìŠ¤ ì¶œì²˜ ìš”ì•½
def list_news_sources(*args, **kwargs):
    news_chunks = get_chunks_by_type("news")
    if not news_chunks:
        return "ë‰´ìŠ¤ ì¶œì²˜ê°€ ì—†ìŠµë‹ˆë‹¤."
    titles = [f"- {c.get('title', '[ì œëª© ì—†ìŒ]')}" for c in news_chunks if c.get("title")]
    return "ì˜¤ëŠ˜ ë‰´ìŠ¤ ëª©ë¡:\n" + "\n".join(titles)

# ë‰´ìŠ¤/ë…¼ë¬¸ ë¹„êµ ìš”ì•½
def compare_news_papers(*args, **kwargs):
    news_chunks = get_chunks_by_type("news")
    paper_chunks = get_chunks_by_type("paper")
    if not news_chunks or not paper_chunks:
        return "ë‰´ìŠ¤ ë˜ëŠ” ë…¼ë¬¸ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤."
    news_text = "\n\n".join([c["text"] for c in news_chunks[:3]])
    paper_text = "\n\n".join([c["text"] for c in paper_chunks[:3]])
    prompt = f"ë‹¤ìŒì€ ë‰´ìŠ¤ì™€ ë…¼ë¬¸ ë‚´ìš©ì…ë‹ˆë‹¤. ê³µí†µì ê³¼ ì°¨ì´ì ì„ ë¹„êµ ìš”ì•½í•´ ì£¼ì„¸ìš”.\n\n[ë‰´ìŠ¤]\n{news_text}\n\n[ë…¼ë¬¸]\n{paper_text}"
    llm = ChatOpenAI(temperature=0.3, openai_api_key=OPENAI_API_KEY)
    return llm.predict(prompt)

# RAG ê¸°ë°˜ ì§ˆì˜ì‘ë‹µ
def rag_qa(query):
    qa = RetrievalQA.from_chain_type(
        llm=ChatOpenAI(temperature=0, openai_api_key=OPENAI_API_KEY),
        retriever=vectordb.as_retriever()
    )
    return qa.run(query)

# ì—ì´ì „íŠ¸ íˆ´ ì •ì˜
tools = [
    Tool(name="news_yok", func=summarize_news, description="ì˜¤ëŠ˜ ë‰´ìŠ¤ ìš”ì•½ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."),
    Tool(name="paper_yok", func=summarize_papers, description="ìµœê·¼ ë…¼ë¬¸ ìš”ì•½ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."),
    Tool(name="qa_tool", func=rag_qa, description="ë‰´ìŠ¤/ë…¼ë¬¸ì„ ê¸°ë°˜ìœ¼ë¡œ ììœ ë¡­ê²Œ ì§ˆë¬¸ì— ë‹µë³€í•©ë‹ˆë‹¤."),
    Tool(name="news_keywords", func=extract_news_keywords, description="ë‰´ìŠ¤ ë³¸ë¬¸ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."),
    Tool(name="news_list", func=list_news_sources, description="ì˜¤ëŠ˜ì˜ ë‰´ìŠ¤ ì œëª© ëª©ë¡ì„ ì¶œë ¥í•©ë‹ˆë‹¤."),
    Tool(name="news_paper_compare", func=compare_news_papers, description="ë‰´ìŠ¤ì™€ ë…¼ë¬¸ ë‚´ìš©ì„ ë¹„êµ ìš”ì•½í•©ë‹ˆë‹¤.")
]

# ì—ì´ì „íŠ¸ ì´ˆê¸°í™”
llm = ChatOpenAI(temperature=0, openai_api_key=OPENAI_API_KEY)
agent = initialize_agent(
    tools=tools,
    llm=llm,
    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
    verbose=True,
    handle_parsing_errors=True
)

# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
if __name__ == "__main__":
    print("ğŸ¤– ì—ì´ì „íŠ¸ í…ŒìŠ¤íŠ¸ ì‹œì‘!")
    print("--- ë‰´ìŠ¤ ìš”ì•½ ---")
    print(agent.run("ì˜¤ëŠ˜ ë‰´ìŠ¤ ìš”ì•½í•´ì¤˜"))
    print("\n--- ë…¼ë¬¸ ìš”ì•½ ---")
    print(agent.run("ìµœê·¼ ë…¼ë¬¸ ë‚´ìš© ìš”ì•½í•´ì¤˜"))
    print("\n--- ììœ  ì§ˆì˜ì‘ë‹µ ---")
    print(agent.run("AI ê´€ë ¨ ì •ì±…ì´ í¬í•¨ëœ ë‰´ìŠ¤ê°€ ìˆì—ˆì–´?"))
    print("\n--- ë‰´ìŠ¤ í‚¤ì›Œë“œ ---")
    print(agent.run("ë‰´ìŠ¤ì—ì„œ í‚¤ì›Œë“œë§Œ ë½‘ì•„ì¤˜"))
    print("\n--- ë‰´ìŠ¤ ì¶œì²˜ ëª©ë¡ ---")
    print(agent.run("ì˜¤ëŠ˜ ë‰´ìŠ¤ ì œëª© ì•Œë ¤ì¤˜"))
    print("\n--- ë‰´ìŠ¤ì™€ ë…¼ë¬¸ ë¹„êµ ---")
    print(agent.run("ë‰´ìŠ¤ì™€ ë…¼ë¬¸ì—ì„œ ë‹¤ë£¨ëŠ” ì£¼ì œë¥¼ ë¹„êµí•´ì¤˜"))
